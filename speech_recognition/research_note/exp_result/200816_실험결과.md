# End-to-end accented speech recognition
Baidu의 [deep speech2](https://scholar.google.co.kr/scholar?cluster=16030706496972570658&hl=ko&as_sdt=0,5)를 바탕으로 모델을 만드는 것은 완료했고 성능이 어느정도 나오는지를 확인하기 위하여 여러번 실험을 진행하였다.  

WER은 대략 90%정도로 10개의 단어 중에서 1개 밖에 맞치지 못하는 수준이다. 아주 처참하다..  

우선 Batch size는 32로 고정시켰는데, batch size를 64로 올리게 된다면 'cuda out of memory' 에러가 발생하여 학습이 진행되지 않는다. LangTech서버의 컴퓨터 성능이 뛰어난 것으로 알고 있는데 학습이 왜 진행되지 않는지 더 알아볼 필요가 있다. 필요하다면 input feature와 model을 바꿔야할 수도 있다.  

Learning rate는 0.001과 0.0001로 진행을 했는데, 예상과는 다르게 learning rate를 바꾸는 것이 결과에 큰 영향을 끼치는 것 같지는 않았다. 두 learning rate 모두 일정 epoch이 지나면 cost가 제대로 낮아지지 않고 있다.  

또 다른 문제점은 decoder에 있다고 생각한다. 현재는 greedy decoder를 사용하고 있지만, 이는 한가지만의 후보를 취하기 때문에 error가 높을 수도 있다. 따라서 성능이 더욱 좋다고 알려진 beam search decoder를 구현해보도록 노력하자.  

그러기 위해서는 deep speech2의 논문을 자세히 읽어보고 제대로 이해하도록 하자!