# End-to-end accented speech recognition
## 공통
model, parameter등은 동일하게 하고, dataset을 바꿔가며 실험들을 진행하였다.  
실험의 세팅은 다음과 같다.  

- model: 1 layers of Resnet (CNN) + 2 layers of BiGRU (RNN)
- feature: 128 mel filterbanks of mel spectrogram
- data augmentation: spec augmentation with frequency masking and time masking
- RNN hidden dimension: 256
- dropout rate: 0.2
- learning rate: 0.0001
- batch size: 32
- loss function: CTC loss
- optimizer: AdamW
- number of classes: 29 (A-Z, apostrophe, space, blank)
- edit distance: levenshtein distance
- decoder: greedy decoder

## 실험1
- commonvoice
- random split
- accent class: 1 (US)
- dataset (8:1:1)  
(1) train set: 80000 files (99 hours)  
(2) validation set: 10000 files (12 hours)  
(3) test set: 10000 files (12 hours)  
- epoch: 100
- test loss: 1.214157
- CER: 35.69%
- WER: 81.04%

## 실험2
- commonvoice
- model: 3 layers of Resnet (CNN) + 5 layers of BiGRU (RNN)
- accent class: 5 (Australia, Canada, England, India, US)
- random split
- dataset (8:1:1)  
(1) train set: 80000 files (101 hours)  
(2) validation set: 10000 files (14 hours)  
(3) test set: 10000 files (13 hours)  
- epoch: 100
- test loss: 1.203911
- CER: 35.14%
- WER: 79.43%

## 실험3
- librispeech
- dataset  
(1) train set: 28539 files (101 hours)  
(2) validation set: 2703 files (5 hours)  
(3) test set: 2620 files (5 hours)  
- epoch: 100
- test loss: 0.689258
- CER: 20.79%
- WER: 58.85%

## 실험4
- commonvoice
- accent class: 5 (Australia, Canada, England, India, US)
- pre-splitted dataset
- dataset  
(1) train set:  124332 files (189 hours)  
(2) validation set:  1875 files (3 hours)  
(3) test set:  1227 files (2 hours)  
- epoch: 100
- test loss: 1.443056
- CER: 42.11%
- WER: 85.59%

## conclusion
- 5개의 accent class(Australia, Canada, England, India, US) -> 단일 accent class(US)로의 변화가 성능향상을 가져오지 않는다.
- 동일 환경에서 commonvoice -> librispeech로 data를 바꿀 시 성능향상이 크게 일어난다 (대략 20%정도의 성능향상)
- underfitting 문제일까?  
-> 해결책  
(1) model을 복잡하게 만들자  
(2) regularization을 줄여보자  
(3) epoch을 늘려 training을 충분히 하자  
(4) additional feature를 추가해보자  
